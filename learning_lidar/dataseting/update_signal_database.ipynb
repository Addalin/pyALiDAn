{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast_funcs not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import learning_lidar.utils.global_settings as gs\n",
    "import learning_lidar.utils.vis_utils as vis_utils\n",
    "import pandas as pd\n",
    "import learning_lidar.preprocessing.preprocessing as prep\n",
    "import learning_lidar.preprocessing.preprocessing_utils as prep_utils\n",
    "%matplotlib inline\n",
    "from learning_lidar.generation.daily_signals_generations_utils import  calc_poiss_measurement,calc_range_corr_measurement\n",
    "import learning_lidar.generation.generation_utils as gen_utils\n",
    "import learning_lidar.dataseting.dataseting as dataseting\n",
    "import learning_lidar.utils.xr_utils as xr_utils\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "vis_utils.set_visualization_settings()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Imports\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Set parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\addalin\\\\Dropbox\\\\Lidar\\\\lidar_learning\\\\data'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_name = 'haifa'\n",
    "station = gs.Station(station_name)\n",
    "wavelengths = gs.LAMBDA_nm().get_elastic()\n",
    "\n",
    "main_folder = os.path.dirname(os.path.abspath(os.path.curdir))\n",
    "data_folder = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(os.path.curdir))), 'data')\n",
    "data_folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Calculate poisson on \"clear\" signals, without background, for the given period.\n",
    "Adding range corrected with applies poisson noise to signal database\n",
    "# TODO: ADD this to generation.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "start_date = datetime(2017, 9, 1)\n",
    "end_date = datetime(2017, 10, 31)\n",
    "dates = pd.date_range(start_date,end_date,freq='D')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "CALC_STATS=False\n",
    "if CALC_STATS:\n",
    "    base_folder = station.gen_signal_dataset\n",
    "    paths = [os.path.join(prep.get_month_folder_name(base_folder, dt),\n",
    "     gen_utils.get_gen_dataset_file_name(station, dt, data_source='signal')) for dt in dates]\n",
    "    mean = np.zeros(3)\n",
    "    std = np.zeros(3)\n",
    "    norm_scale = 1 / len(dates)\n",
    "\n",
    "    for cur_date,nc_path in zip(dates,paths):\n",
    "        signal_ds = prep.load_dataset(nc_path)\n",
    "        signal_ds\n",
    "        pn_ds = calc_poiss_measurement(station, cur_date, signal_ds.p)  # lidar measurement: pn ~Poiss(mu_p)\n",
    "        pr2n_ds = calc_range_corr_measurement(station, cur_date, pn_ds, signal_ds.r2) # range corrected measurement: pr2n = pn * r^2\n",
    "        pr2n_ds.attrs['info']+=' - w.o. background'\n",
    "        mean += pr2n_ds.mean(dim={'Height', 'Time'}).values\n",
    "        std += pr2n_ds.std(dim={'Height', 'Time'}).values\n",
    "        signal_ds = signal_ds.assign(range_corr_p =pr2n_ds)\n",
    "        gen_utils.save_generated_dataset(station, signal_ds,\n",
    "                                         data_source='signal',\n",
    "                                         save_mode='both',\n",
    "                                         profiles=['range_corr_p'])\n",
    "\n",
    "    mean *= norm_scale\n",
    "    std *= norm_scale"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Statistics for a period of the dataset\n",
    "> Loading the statistics database created in dataseting.py\n",
    "# TODO: ADD this to statistics calculation\n",
    "# TODO: ADD `range_corr_p` as  column to dataseting.py (gen_csv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   wavelength  p_signal_mean  p_signal_std  p_signal_min  p_signal_max  \\\n0       355.0      88.280901    812.655000      0.003964  21699.117680   \n1       532.0      94.206550    844.996252      0.008764  23194.884770   \n2      1064.0      25.641477    223.603415      0.001039   6651.830518   \n3         NaN            NaN           NaN           NaN           NaN   \n4         NaN            NaN           NaN           NaN           NaN   \n5         NaN            NaN           NaN           NaN           NaN   \n6         NaN            NaN           NaN           NaN           NaN   \n\n   range_corr_signal_mean  range_corr_signal_std  range_corr_signal_min  \\\n0               15.549797              24.042348               0.936831   \n1               22.552368              28.921022               2.071057   \n2                7.308976               9.713228               0.245562   \n3                     NaN                    NaN                    NaN   \n4                     NaN                    NaN                    NaN   \n5                     NaN                    NaN                    NaN   \n6                     NaN                    NaN                    NaN   \n\n   range_corr_signal_max  range_corr_p_signal_mean  ...  p_bg_bg_min  \\\n0             134.568434                 15.533479  ...     0.000403   \n1             145.640789                 22.529013  ...     0.000725   \n2              47.037022                  7.304823  ...     0.000283   \n3                    NaN                       NaN  ...          NaN   \n4                    NaN                       NaN  ...          NaN   \n5                    NaN                       NaN  ...          NaN   \n6                    NaN                       NaN  ...          NaN   \n\n   p_bg_bg_max      LC_mean       LC_std        LC_min       LC_max  \\\n0     0.595537  10892.71745   765.014962   9648.912511  12252.52209   \n1     1.365883  32985.83342  2403.349800  29265.571770  37062.94491   \n2     0.146088  25442.85222  1830.105197  22457.129270  28573.14919   \n3          NaN          NaN          NaN           NaN          NaN   \n4          NaN          NaN          NaN           NaN          NaN   \n5          NaN          NaN          NaN           NaN          NaN   \n6          NaN          NaN          NaN           NaN          NaN   \n\n   p_bg_r2_bg_mean  p_bg_r2_bg_std  p_bg_r2_bg_min  p_bg_r2_bg_max  \n0        11.142602       10.655540        0.000423       51.882701  \n1        28.980261       27.025179        0.001372      122.899301  \n2         2.017860        2.238724        0.000007       13.191458  \n3              NaN             NaN             NaN             NaN  \n4              NaN             NaN             NaN             NaN  \n5              NaN             NaN             NaN             NaN  \n6              NaN             NaN             NaN             NaN  \n\n[7 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wavelength</th>\n      <th>p_signal_mean</th>\n      <th>p_signal_std</th>\n      <th>p_signal_min</th>\n      <th>p_signal_max</th>\n      <th>range_corr_signal_mean</th>\n      <th>range_corr_signal_std</th>\n      <th>range_corr_signal_min</th>\n      <th>range_corr_signal_max</th>\n      <th>range_corr_p_signal_mean</th>\n      <th>...</th>\n      <th>p_bg_bg_min</th>\n      <th>p_bg_bg_max</th>\n      <th>LC_mean</th>\n      <th>LC_std</th>\n      <th>LC_min</th>\n      <th>LC_max</th>\n      <th>p_bg_r2_bg_mean</th>\n      <th>p_bg_r2_bg_std</th>\n      <th>p_bg_r2_bg_min</th>\n      <th>p_bg_r2_bg_max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>355.0</td>\n      <td>88.280901</td>\n      <td>812.655000</td>\n      <td>0.003964</td>\n      <td>21699.117680</td>\n      <td>15.549797</td>\n      <td>24.042348</td>\n      <td>0.936831</td>\n      <td>134.568434</td>\n      <td>15.533479</td>\n      <td>...</td>\n      <td>0.000403</td>\n      <td>0.595537</td>\n      <td>10892.71745</td>\n      <td>765.014962</td>\n      <td>9648.912511</td>\n      <td>12252.52209</td>\n      <td>11.142602</td>\n      <td>10.655540</td>\n      <td>0.000423</td>\n      <td>51.882701</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>532.0</td>\n      <td>94.206550</td>\n      <td>844.996252</td>\n      <td>0.008764</td>\n      <td>23194.884770</td>\n      <td>22.552368</td>\n      <td>28.921022</td>\n      <td>2.071057</td>\n      <td>145.640789</td>\n      <td>22.529013</td>\n      <td>...</td>\n      <td>0.000725</td>\n      <td>1.365883</td>\n      <td>32985.83342</td>\n      <td>2403.349800</td>\n      <td>29265.571770</td>\n      <td>37062.94491</td>\n      <td>28.980261</td>\n      <td>27.025179</td>\n      <td>0.001372</td>\n      <td>122.899301</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1064.0</td>\n      <td>25.641477</td>\n      <td>223.603415</td>\n      <td>0.001039</td>\n      <td>6651.830518</td>\n      <td>7.308976</td>\n      <td>9.713228</td>\n      <td>0.245562</td>\n      <td>47.037022</td>\n      <td>7.304823</td>\n      <td>...</td>\n      <td>0.000283</td>\n      <td>0.146088</td>\n      <td>25442.85222</td>\n      <td>1830.105197</td>\n      <td>22457.129270</td>\n      <td>28573.14919</td>\n      <td>2.017860</td>\n      <td>2.238724</td>\n      <td>0.000007</td>\n      <td>13.191458</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows Ã— 33 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_fname = f\"stats_gen_{station.name}_{start_date.strftime('%Y-%m-%d')}_{end_date.strftime('%Y-%m-%d')}.csv\"\n",
    "csv_stats_path = os.path.join(data_folder, stats_fname)\n",
    "df_stats = pd.read_csv(csv_stats_path)\n",
    "df_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if CALC_STATS:\n",
    "    df_stats['range_corr_p_mean'] = mean\n",
    "    df_stats['range_corr_p_std'] = std\n",
    "    df_stats\n",
    "    df_stats.to_csv(csv_stats_path,index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Split files per time for each file in the database per sample time\n",
    "# TODO: move this to a new function prepare_generated_samples() after calling to create_generated_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "CREATE_SAMPLES = False\n",
    "if CREATE_SAMPLES:\n",
    "    dataseting.prepare_generated_samples(station,start_date,end_date)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Update the current train and test datasets according to new paths in the generated dataset\n",
    "> such that the keys are not changed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "gen_base_name = f\"dataset_gen_{station_name}_{start_date.strftime('%Y-%m-%d')}_{end_date.strftime('%Y-%m-%d')}\"\n",
    "csv_gen_path = os.path.join(data_folder,f\"{gen_base_name}.csv\")\n",
    "csv_gen_train_path = os.path.join(data_folder,f\"{gen_base_name}_train.csv\")\n",
    "csv_gen_test_path = os.path.join(data_folder,f\"{gen_base_name}_test.csv\")\n",
    "csv_gen_path, csv_gen_train_path,csv_gen_test_path\n",
    "\n",
    "df_gen = pd.read_csv(csv_gen_path)\n",
    "df_gen_train = pd.read_csv(csv_gen_train_path)\n",
    "df_gen_test = pd.read_csv(csv_gen_test_path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# update p_bg with r2 multiplication\n",
    "> such that the keys are not changed.\n",
    "> TODO: If this improves the learning stage add it to the generation process and in dataseting proccess (including stats calculations)\n",
    "> TODO: it is better to use save_dataset2timesplits() in dataseting.py when doing time splis.\n",
    ">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "CREATE_PBG_R2 =True\n",
    "df_gen['date'] = pd.to_datetime(df_gen['date'])\n",
    "grps_days = df_gen.groupby('date').groups\n",
    "mean = np.zeros(3)\n",
    "std = np.zeros(3)\n",
    "min = np.zeros(3)\n",
    "max = np.zeros(3)\n",
    "for day_dt, inds in grps_days.items():\n",
    "    wavelengths_grps =  df_gen.iloc[inds].groupby('wavelength').groups\n",
    "    tslices = dataseting.get_time_splits(station, day_dt, day_dt, '30min')\n",
    "    norm_scale = 1/(len(grps_days)*len(tslices))\n",
    "    r2_ds = prep_utils.calc_r2_ds(station,day_dt)\n",
    "    for ind,tslice in enumerate(tslices):\n",
    "        for ind_wav,wavelength in enumerate(wavelengths_grps):\n",
    "            ind_gen = wavelengths_grps[wavelength][ind]\n",
    "            path = df_gen.iloc[ind_gen]['bg_path']\n",
    "            path = path.replace('E:','D:')\n",
    "            bg_ds = prep.load_dataset(path)\n",
    "            if CREATE_PBG_R2:\n",
    "                hslice = slice (bg_ds.Height[0].values,bg_ds.Height[-1].values )\n",
    "                r2_ds_slice = r2_ds.sel(Height = hslice, Time =tslice, Wavelength = wavelength)\n",
    "                p_bg_r2 = xr.apply_ufunc(lambda p,r2 : p*r2,bg_ds.p_bg, r2_ds_slice, keep_attrs=True).\\\n",
    "                    assign_attrs({'long_name':r'$<p_{\\rm bg}>$'+ r'$\\cdot r^2$',\n",
    "                               'units':r'$\\rm photons \\cdot km^2$','info':'Daily averaged background signal - range corrected'})\n",
    "                bg_ds = bg_ds.assign(p_bg_r2=p_bg_r2)\n",
    "                xr_utils.save_dataset(dataset=bg_ds, nc_path=path)\n",
    "\n",
    "            # update stats values:\n",
    "            mean[ind_wav]+= norm_scale * bg_ds.p_bg_r2.mean(dim={'Height', 'Time'}).values\n",
    "            std[ind_wav]+= norm_scale * bg_ds.p_bg_r2.std(dim={'Height', 'Time'}).values\n",
    "            min[ind_wav]+= norm_scale * bg_ds.p_bg_r2.min(dim={'Height', 'Time'}).values\n",
    "            max[ind_wav]+= norm_scale * bg_ds.p_bg_r2.max(dim={'Height', 'Time'}).values\n",
    "cols = ['p_bg_r2_bg_mean','p_bg_r2_bg_std','p_bg_r2_bg_min','p_bg_r2_bg_max']\n",
    "df_stats_p_pg = pd.DataFrame(data=[mean,std,min,max], index=cols).T\n",
    "new_df_stats = pd.concat([df_stats,df_stats_p_pg],axis=1)\n",
    "new_df_stats.to_csv(csv_stats_path,index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "new_df_stats.to_csv(csv_stats_path,index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lidar",
   "language": "python",
   "display_name": "lidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}